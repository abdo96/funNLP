
<center>
<img style="border-radius: 0.3125em;
box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);"
src="./data/.logo image/.img.jpg" width="180">
<br>
<div style="color:orange; border-bottom: 1px solid #d9d9d9;
display: inline-block;
color: #999;
padding: 2px;">NLP Migrant Workers Paradise</div>
</center>
<br>

[![](https://img.shields.io/github/stars/fighting41love/funnlp?style=social)](https://github.com/fighting41love/funnlp)
[![](https://img.shields.io/badge/dynamic/json?color=blue&label=%E7%9F%A5%E4%B9%8E%E5%85%B3%E6%B3%A8&query= %24.data.totalSubs&url=https%3A%2F%2Fapi.spencerwoo.com%2Fsubstats%2F%3Fsource%3Dzhihu%26queryKey%3Dmountain-blue-64)](https://www.zhihu.com/people/mountain -blue-64)
[![](data/.logo image/.donation image/.Citations-487-red.svg)](https://scholar.google.com/citations?hl=en&user=aqZdfDUAAAAJ)

[![](data/.logo image/.donation image/.Home-%E4%BA%BA%E7%94%9F%E6%B5%AA%E8%B4%B9%E6%8C%87%E5 %8D%97-brightgreen.svg)](http://fighting41love.github.io/archives/)
[![](data/.logo image/.donation image/.%E7%8C%8E%E9%80%81%E9%97%A8-CV-orange.svg)](http://fighting41love.github .io/)
<!-- [![](https://img.shields.io/badge/dynamic/json?color=blueviolet&label=github%20followers&query=%24.data.totalSubs&url=https%3A%2F%2Fapi.spencerwoo. com%2Fsubstats%2F%3Fsource%3Dgithub%26queryKey%3Dfighting41love)](https://github.com/fighting41love) -->
<!-- [![](https://img.shields.io/badge/Homepage-%E4%BA%BA%E7%94%9F%E6%B5%AA%E8%B4%B9%E6% 8C%87%E5%8D%97-brightgreen)](http://fighting41love.github.io/archives/) -->

### The Most Powerful NLP-Weapon Arsenal
## NLP Migrant Workers' Paradise: Almost the most complete Chinese NLP resource library
In the process of getting started and getting familiar with NLP, I used a lot of packages on github, so I sorted it out and shared it here.

Many bags are very interesting and worth collecting, satisfying everyone's collection addiction!
If you find it useful, please share and star:star:, thank you!

Long-term irregular updates, welcome to watch and fork! :heart::heart::heart:

 
| :eggplant: :cherries: :pear: :tangerine:                   ;                |
| ---- | ---- |
| * [corpus](#corpus) <br> * [thesaurus and lexical tools](#thesaurus and lexical tools) <br> * [pretrained language model](#pretrained language model) <br> * [ extract](#extract) <br> * [knowledge graph](#knowledge graph) <br> * [text generation](#text generation) <br> * [text summary](#text summary) <br> * [ Smart Q&A](#智能问题) <br> * [Text Error Correction](#Text Error Correction) | * [Document Processing](#Document Processing) <br> * [Form Processing](#Form Processing) <br> * [Text Matching](#Text Matching) <br> * [Text Data Enhancement](#Text Data Enhancement) <br> * [Text Retrieval](#Text Retrieval) <br> * [Reading Comprehension](#Reading Comprehension ) <br> * [Sentiment Analysis](#Emotion Analysis) <br> * [Common Regular Expression](#Common Regular Expression) <br> * [Voice Processing](#Voice Processing) |
| * [Common regular expressions](#Common regular expressions) <br> * [Event extraction](#Event extraction) <br> * [Machine translation](#Machine translation) <br> * [Number conversion]( #digitalconversion) <br> * [Anaphora resolution](#Anaphora resolution) <br> * [Text clustering](#Text clustering) <br> * [Text classification](#Text classification) <br> * [knowledge reasoning](#knowledge reasoning) <br> * [interpretable NLP](#interpretable natural language processing) <br> * [text adversarial attack](#text adversarial attack) | * [text visualization](# Text Visualization) <br> * [Text Markup Tool](#Text Markup Tool) <br> * [Comprehensive Tool](#Comprehensive Tool) <br> * [Funny Funny Tool](#Funny Funny Tool) <br> * [Course report interview etc.](#course report interview etc.) <br> * [competition](#competition) <br> * [financial NLP](#financial natural language processing) <br> * [medical NLP](#medical Natural Language Processing) <br> * [Legal NLP](#法natural language processing) <br> * [Text Generated Image](#Text Generated Image) <br> * [Other](#Other) |

<!--
Table of Contents
==================
<table border="0">
<tr>
<td><b style="font-size:30px">:star:</b></td>
<td><b style="font-size:30px">:star::star:</b></td>
<td><b style="font-size:30px">:star::star::star:</b></td>
<td><b style="font-size:30px">:star::star::star::star:</b></td>
</tr>
<tr>
<td>

<!--ts-->
<!-- * [corpus](#corpus)
* [Thesaurus and Lexical Tools](#Thesaurus and Lexical Tools)
* [Pre-trained language model](#Pre-trained language model)
* [extract](#extract)
* [Knowledge Graph](#Knowledge Graph)
* [text generation](#text generation)
* [text summary](#text summary)
* [Smart Q&A](#智能问题)
* [text correction](#text correction) -->


<!--te-->

</td>

<td>

<!--ts-->

<!-- * [document processing](#document processing)
* [Form Handling](#Form Handling)
* [text match](#text match)
* [text data augmentation](#text data augmentation)
* [text search](#text search)
* [reading comprehension](#reading comprehension)
* [Sentiment Analysis] (#Sentiment Analysis)
* [Common regular expressions](#Common regular expressions)
* [speech processing](#speech processing) -->
<!--te-->

</td>

<td>
 
<!--ts-->
<!-- * [Common regular expressions](#Common regular expressions)
* [event extraction](#event extraction)
* [machine translation] (#machine translation)
* [digital conversion](#digital conversion)
* [reference resolution](#reference resolution)
* [text clustering](#text clustering)
* [Text Classification](#Text Classification)
* [knowledge reasoning](#knowledge reasoning)
* [Interpretable NLP] (# Interpretable Natural Language Processing)
* [Text against attack](#Text against attack) -->

<!--te-->
 
</td>

<td>
 
<!--ts-->
<!--
* [textvisualization](#textvisualization)
* [Text Annotation Tool](#Text Annotation Tool)
* [Comprehensive Tools](#Comprehensive Tools)
* [Funny funny tools] (#interesting funny tools)
* [Course report interview, etc.](#Course report interview, etc.)
* [competition](#competition)
* [Financial NLP] (#financial natural language processing)
* [Medical NLP] (#Medical Natural Language Processing)
* [Legal NLP] (#legalnatural language processing)
* [other](#other) -->

<!--te-->
 
<!-- </td>

</tr>
</table> -->




----

# corpus

| resource name (Name) | description (Description) | link |
| :--- | :------ | :--- |
| Name Corpus | | [wainshine/Chinese-Names-Corpus](https://github.com/wainshine/Chinese-Names-Corpus) |
| Chinese-Word-Vectors | Various Chinese word vectors | [github repo](https://github.com/Embedding/Chinese-Word-Vectors) |
| Chinese chat corpus| This database includes Douban Duolun, PTT gossip corpus, Qingyun corpus, TV drama dialogue corpus, Tieba forum reply corpus, Weibo corpus, little yellow chicken corpus| [link](https://github.com /codemayq/chaotbot_corpus_Chinese) |
| Chinese rumor data| In this data file, each row is a rumor data in json format| [github](https://github.com/thunlp/Chinese_Rumor_Dataset) |
| Chinese question and answer dataset | | [Link](https://pan.baidu.com/s/1QUsKcFWZ7Tg1dk_AbldZ1A) extraction code 2dva |
| WeChat official account corpus| 3G corpus, including some articles of WeChat official account captured from the web, HTML has been removed, and only plain text is included. One article per line, in JSON format, name is the name of the WeChat official account, account is the ID of the WeChat official account, title is the title, and content is the text | [github](https://github.com/nonamestreet/weixin_public_corpus) |
| Chinese natural language processing corpus, data set | | [github](https://github.com/SophonPlus/ChineseNlpCorpus) |
| Task-based dialogue English data set | [The most complete task-based dialogue data set] mainly introduces a task-based dialogue data set, which covers the main data sets of all commonly used data sets in the field of task-based dialogue. information. In addition, in order to help researchers better grasp the context of field progress, we present the State-of-the-art experimental results on several datasets in the form of Leaderboard. | [github](https://github.com/AtmaHou/Task-Oriented-Dialogue-Dataset-Survey) |
| Speech recognition corpus generation tool | Create automatic speech recognition (ASR) corpus from online videos with audio/subtitles | [github](https://github.com/yc9701/pansori) |
| LitBankNLP Dataset | A corpus of 100 labeled English novels supporting natural language processing and computational humanities tasks | [github](https://github.com/dbamman/litbank) |
| Chinese ULMFiT | Sentiment Analysis Text Classification Corpus and Model | [github](https://github.com/bigboNed3/chinese_ulmfit) |
| Province, city, town administrative division data with pinyin annotation| | [github](https://github.com/xiangyuecn/AreaCity-JsSpider-StatsGov) |
| Education Industry News Automatic Abstract Corpus | | [github](https://github.com/wonderfulsuccess/chinese_abstrative_corpus) |
| Chinese Natural Language Processing Dataset | | [github](https://github.com/InsaneLife/ChineseNLPCorpus) |
| Baidu Zhizhi Q&A Corpus| More than 5.8 million questions, 9.38 million answers, 5800 classification labels. Based on this Q&A corpus, it can support a variety of applications, such as chatting Q&A, logic mining | [github](https://github.com/liuhuanyong/MiningZhiDaoQACorpus) |
| Wiki Large-Scale Parallel Text Corpus | 85 languages, 1620 language pairs, 135M contrasting sentences | [github](https://github.com/facebookresearch/LASER/tree/master/tasks/WikiMatrix)
| Ancient Poetry Thesaurus| | [github repo](https://github.com/panhaiqi/AncientPoetry) <br>[More complete ancient poetry thesaurus](https://github.com/chinese-poetry/chinese-poetry )
| Loading Wikipedia data with low memory | Loading 17GB+ English Wikipedia corpus with the new version of nlp library only takes up 9MB memory traversal speed 2-3 Gbit/s | [github](https://gistgithub.com/thomwolf/13ca2b2b172b2d17ac66685aa2eeba62) |
| Couplet data| 700,000 couplets, over 700,000 pairs of couplets| [github](https://github.com/wb14123/couplet-dataset) |
| "Color Matching Dictionary" dataset | | [github](https://github.com/mattdesl/dictionary-of-colour-combinations) |
| 42GB of JD Customer Service Dialogue Data (CSDD) | | [github](https://github.com/jd-aig/nlp_baai/tree/master/pretrained_models_and_embeddings) |
| 700,000 couplet data| | [link](https://github.com/wb14123/couplet-dataset) |
| Username Blacklist | | [github](https://github.com/marteinn/The-Big-Username-Blacklist) |
| Dependent Syntactic Analysis Corpus | 40,000 high-quality labeled data | [Homepage](http//hlt.suda.edu.cn/indexphp/Nlpcc-2019-shared-task) |
| People's Daily Corpus Processing Toolset | | [github](https://github.com/howl-anderson/tools_for_corpus_of_people_daily) |
| Fake News Dataset fake news corpus | | [github](https://github.com/several27/FakeNewsCorpus) |
| Poetry Quality Evaluation / Fine-grained Emotional Poetry Corpus | | [github](https://github.com/THUNLP-AIPoet/Datasets) |
| Open tasks related to Chinese natural language processing | Datasets and current best results | [github](https://github.com/didi/ChineseNLP) |
| Chinese abbreviation dataset| | [github](https://github.com/zhangyics/Chinese-abbreviation-dataset) |
| Chinese Task Benchmark Evaluation | Representative Dataset - Benchmark (Pre-training) Model - Corpus - Baseline - Toolkit - Leaderboard | [github](https://github.com/CLUEbenchmark/CLUE) |
| Chinese Rumor Database| | [github](https://github.com/thunlp/Chinese_Rumor_Dataset) |
| CLUEDatasetSearch | Chinese and English NLP datasets search all Chinese NLP datasets, with commonly used English NLP datasets | [github](https://github.com/CLUEbenchmark/CLUEDatasetSearch) |
| Multi-Document Summarization Dataset | | [github](https://github.com/complementizer/wcep-mds-dataset) |
| Make Everyone "Polite" Politeness Transfer Task | Transform impolite sentences into polite sentences while preserving meaning, providing a dataset with 139M+ instances | [paper and code](https://arxiv .org/abs/200414257) |
| Cantonese/English Conversational Bilingual Corpus | | [github](https://github.com/khiajohnson/SpiCE-Corpus) |
| List of Chinese NLP datasets | | [github](https://github.com/OYE93/Chinese-NLP-Corpus) |
| Nomenclature recognition datasets of person-like names/place names/organization names| | [github](https://github.com/LG-1/video_music_book_datasets) |
| Chinese Language Comprehension Evaluation Benchmark | Including Representative Datasets & Benchmark Models & Corpus & Leaderboards | [github](https://github.com/brightmart/ChineseGLUE) |
| OpenCLaP multi-domain open source Chinese pre-trained language model warehouse | Civil documents, criminal documents, Baidu Encyclopedia | [github](https://github.com/thunlp/OpenCLaP) |
| Chinese full words cover BERT and two reading comprehension data | DRCD dataset: released by Delta Research Institute, Taiwan, China, in the same form as SQuAD, it is an extractive reading comprehension dataset based on traditional Chinese. <br>CMRC 2018 dataset: Chinese machine reading comprehension data released by the Xunfei Joint Laboratory of Harbin Institute of Technology. According to a given question, the system needs to extract fragments from the text as answers, in the same form as SQuAD. | [github](https://github.com/ymcui/Chinese-BERT-wwm) |
| Dakshina Dataset | A Latin/Native Script Parallel Dataset Collection for Twelve South Asian Languages ​​| [github](https://github.com/google-research-datasets/dakshina) |
| OPUS-100 | English-centric multilingual (100 types) parallel corpus | [github](https://github.com/EdinburghNLP/opus-100-corpus) |
| Chinese Reading Comprehension Datasets| | [github](https://github.com/ymcui/Chinese-RC-Datasets) |
| Chinese natural language processing vector collection | | [github](https://github.com/liuhuanyong/ChineseEmbedding) |
| Chinese Language Comprehension Evaluation Benchmark | Including representative data sets, benchmark (pre-training) models, corpus, ranking list | [github](https://github.com/CLUEbenchmark/CLUE) |
| Large list of NLP datasets/benchmark tasks | | [github](https://quantumstatcom/dataset/datasethtml) |
| LitBankNLP Dataset | A corpus of 100 labeled English novels supporting natural language processing and computational humanities tasks | [github](https://github.com/dbamman/litbank) |
|700,000 couplet data||[github](https://github.com/wb14123/couplet-dataset)|
|Classical Chinese (Ancient Chinese)-Modern Parallel Corpus|Short chapters include "The Analects of Confucius", "Mencius", "Zuo Zhuan" and other short ancient books, which have been merged with "Zi Zhi Tong Jian"|[github](https ://github.com/NiuTrans/Classical-Modern)|
|COLDDateset, Chinese offensive language detection data set|covers topics such as race, gender and region, and the data will be released after the paper is published|[paper](https://arxiv.org/pdf/2201.06025.pdf)|

# Thesaurus and lexical tools

| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
| textfilter | Sensitive word filtering in Chinese and English | [observerss/textfilter](https://github.com/observerss/textfilter) |
| Name extraction function | Chinese (modern and ancient) names, Japanese names, Chinese surnames and first names, titles (big aunt, little aunt, etc.), English -> Chinese name (Li John), idiom dictionary| [cocoNLP](https ://github.com/fighting41love/cocoNLP) |
| Chinese Abbreviation Library| National People's Congress: National People's Congress; China: People's Republic of China; Women's Tennis: Women's/n Tennis/n Game/vn | [github](https://github.com/zhangyics/Chinese-abbreviation -dataset/blob/master/dev_set.txt) |
| Chinese Chaizi Dictionary| Chinese character dismantling method (1) dismantling method (2) dismantling method (3) dismantling hands, rebuking, rebuking, rebuking, rebuking and rebuking | [kfcd/chaizi](https://github.com/kfcd/chaizi) |
| Vocabulary emotion value| Spring water: 0.400704566541 <br> Plenty: 0.37006739587 | [rainarch/SentiBridge](https://github.com/rainarch/SentiBridge/blob/master/Entity_Emotion_Express/CCF_data/pair_mine_result) |
| Chinese thesaurus, stop words, sensitive words| | [dongxiexidian/Chinese](https://github.com/fighting41love/Chinese_from_dongxiexidian) |
| python-pinyin | Convert Chinese characters to pinyin | [mozillazg/python-pinyin](https://github.com/mozillazg/python-pinyin) |
| zhtools | Chinese traditional and simplified conversion | [skydark/nstools](https://github.com/skydark/nstools/tree/master/zhtools) |
| English simulation Chinese pronunciation engine | say wo i ni #说：我爱你| [tinyfool/ChineseWithEnglish](https://github.com/tinyfool/ChineseWithEnglish) |
| chinese_dictionary | Thesaurus, antonym, negative thesaurus | [guotong1988/chinese_dictionary](https://github.com/guotong1988/chinese_dictionary) |
| wordninja | English string segmentation and word extraction without spaces | [wordninja](https://github.com/keredson/wordninja) |
| Car brand, auto parts related vocabulary | | [data](https://github.com/fighting41love/funNLP/tree/master/data)| Encyclopedia of company names| | [github repo](https://github.com /wainshine/Company-Names-Corpus)
| Thesaurus compiled by THU| IT thesaurus, financial thesaurus, idiom thesaurus, place nouns, historical celebrities, poetry thesaurus, medical thesaurus, diet thesaurus, legal thesaurus, automobile thesaurus, animal words Library | [link](http://thuctc.thunlp.org/) |
| Crime legal terms and classification model| Contains 856 crime knowledge graphs, crime prediction based on 2.8 million crime training database, 13 types of question classification and legal information question and answer function based on 20W legal question and answer pairs| [github](https://github .com/liuhuanyong/CrimeKgAssitant) |
| Word segmentation corpus + code| | [Baidu network disk link](https://pan.baidu.com/s/1MXZONaLgeaw0_TxZZDAIYQ) - extraction code pea6 |
| Chinese word segmentation + part-of-speech tagging based on Bi-LSTM + CRF | keras implementation | [link](https://github.com/GlassyWing/bi-lstm-crf) |
| Chinese word segmentation and part-of-speech tagging based on Universal Transformer + CRF| | [link](https://github.com/GlassyWing/transformer-word-segmenter) |
| Fast neural network word segmentation package | java version | [](https://github.com/yaoguangluo/NeroParser) |
| chinese-xinhua | Chinese Xinhua dictionary database and api, including commonly used Xiehouyu, idioms, words and Chinese characters | [github](https://github.com/pwxcoo/chinese-xinhua) |
| SpaCy Chinese Model| Contains functions such as Parser, NER, syntax tree, etc. Some English packages use spacy's English model. If you want to adapt to Chinese, you may need to use spacy's Chinese model. | [github](https://github.com/howl-anderson/Chinese_models_for_SpaCy) |
| Chinese character data| | [github](https://github.com/skishore/makemeahanzi) |
| Synonyms Chinese Synonyms Toolkit | | [github](https://github.com/huyingxi/Synonyms) |
| HarvestText | Domain adaptive text mining tools (new word discovery-sentiment analysis-entity linking, etc.) | [github](https://github.com/blmoistawinde/HarvestText) |
| word2word | An easy-to-use multilingual word-word pair set in 62 languages/3,564 multilingual pairs | [github](https://github.com/Kyubyong/word2word) |
| Polyphone dictionary data and code| | [github](https://github.com/mozillazg/phrase-pinyin-data) |
| Chinese characters, words, idioms query interface | | [github](https://github.com/netnr/zidian/tree/206028e5ce9a608afc583820df8dc2d1d4b61781) |
| 103976 English vocabulary packages | (sql version, csv version, Excel version) | [github](https://github.com/1eez/103976) |
| Large list of English swear words | | [github](https://github.com/zacanger/profane-words) |
| Word Pinyin Data| | [github](https://github.com/mozillazg/phrase-pinyin-data) |
| Numeral naming library in 186 languages ​​| | [github](https://github.com/google/UniNum) |
| Large-scale database of names from all over the world | | [github](https://github.com/philipperemy/name-dataset) |
| Chinese character feature extractor (featurizer) | Extract the features of Chinese characters (pronunciation features, font features) for deep learning features | [github](https://github.com/howl-anderson/hanzi_char_featurizer) |
| char_featurizer - Chinese character feature extraction tool | | [github](https://github.com/charlesXu86/char_featurizer) |
| The Python interface library of mecab, the CJK word segmentation library | | [github](https://github.com/jeongukjae/python-mecab) |
| g2pC context-based Chinese pronunciation automatic marking module | | [github](https://github.com/Kyubyong/g2pC) |
| ssc, Sound Shape Code | Sound-Shape Code- A Chinese String Similarity Calculation Method Based on "Sound Shape Code"| [version 1](https://github.com/qingyujean/ssc)<br>[version 2] (https://github.com/wenyangchou/SimilarCharactor)<br>[blog/introduction](https://blogcsdnnet/chndata/article/details/41114771) |
| Acquisition of multiple meanings/meaning items of Chinese words and semantic disambiguation of specific sentences based on the encyclopedia knowledge base | | [github](https://github.com/liuhuanyong/WordMultiSenseDisambiguation) |
| Tokenizer fast, customizable text tokenization library | | [github](https://github.com/OpenNMT/Tokenizer) |
| Tokenizers | A state-of-the-art tokenizer with a focus on performance and versatility | [github](https://github.com/huggingface/tokenizers)|
| Realize text "face change" by synonym replacement | | [github](https://github.com/paubric/python-sirajnet) |
| token2index is a powerful lightweight term index library compatible with PyTorch/Tensorflow | | [github](https://github.com/Kaleidophon/token2index) |
| Traditional and Simplified Conversion | | [github](https://github.com/berniey/hanziconv) |
| Cantonese NLP Tool| | [github](https://github.com/jacksonllee/pycantonese)|
|Domain Dictionary|A professional dictionary knowledge base covering 68 fields with a total of 9.16 million words|[github](github.com/liuhuanyong/DomainWordsDict)|



# Pre-training language model & large model
 
| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
|BMList|Big model big list|[github](https://github.com/OpenBMB/BMList)|
| Chinese translation of bert papers | | [link](https://github.com/yuanxiaosc/BERT_Paper_Chinese_Translation) |
| slides of the original author of bert | | [link](https://pan.baidu.com/s/1OSPsIu2oh1iJ-bcXoDZpJQ) |
| Text classification practice | | [github](https://github.com/NLPScott/bert-Chinese-classification-task) |
| bert tutorial text classification tutorial | | [github](https://github.com/Socialbird-AILab/BERT-Classification-Tutorial) |
| bert pytorch implementation | | [github](https://github.com/huggingface/pytorch-pretrained-BERT) |
| bert pytorch implementation | | [github](https://github.com/huggingface/pytorch-pretrained-BERT) |
| BERT generates sentence vectors, BERT does text classification and text similarity calculation | | [github](https://github.com/terrifyzhao/bert-utils) |
| Illustration of bert and ELMO | | [github](https://jalammargithubio/illustrated-bert/) |
| BERT Pre-trained models and downstream applications | | [github](https://github.com/asyml/texar/tree/master/examples/bert) |
| Language/Knowledge Representation Tool BERT & ERNIE | | [github](https://github.com/PaddlePaddle/LARK) |
| Using gpt-2 language model in Kashgari | | [github](https://github.com/BrikerMan/Kashgari) |
| Facebook LAMA | Probes for analyzing factual and commonsense knowledge contained in pretrained language models. Language model analysis, providing a unified access interface for Transformer-XL/BERT/ELMo/GPT pre-trained language models | [github](https://github.com/facebookresearch/LAMA) |
| Chinese GPT2 training code | | [github](https://github.com/Morizeyao/GPT2-Chinese) |
| XLMFacebook's cross-language pre-trained language model | | [github](https://github.com/facebookresearch/XLM) |
| Massive Chinese pre-trained ALBERT model | | [github](https://github.com/brightmart/albert_zh) |
| Transformers 20 | Support TensorFlow 20 and PyTorch's natural language processing pre-training language model (BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNet...) 8 architectures / 33 pre-training models / 102 languages ​​| [github] (https://github.com/huggingface/transformers) |
| 8 papers combing the progress and reflection of BERT related models | | [github](https://wwwmsracn/zh-cn/news/features/bert) |
| French RoBERTa pre-trained language model | French RoBERTa pre-trained language model trained with 138GB corpus | [link](https://camembert-model.fr/) |
| Chinese pre-training ELECTREA model | Pretrain Chinese Model based on confrontational learning | [github](https://github.com/CLUEbenchmark/ELECTRA) |
| albert-chinese-ner | Chinese NER with pre-trained language model ALBERT | [github](https://github.com/ProHiryu/albert-chinese-ner) |
| Open source pretrained language model collection | | [github](https://github.com/ZhuiyiTechnology/pretrained-models) |
| Chinese ELECTRA pre-training model | | [github](https://github.com/ymcui/Chinese-ELECTRA) |
| Predicting the next word with Transformers (BERT, XLNet, Bart, Electra, Roberta, XLM-Roberta) (model comparison) | | [github](https://github.com/renatoviolin/next_word_prediction) |
| TensorFlow Hub | New language models for 40+ languages ​​(including Chinese) | [link](https://tfhub.dev/google/collections/wiki40b-lm/1) |
| UER | Chinese pre-training model warehouse based on different corpora, encoders, and target tasks (including BERT, GPT, ELMO, etc.) | [github](https://github.com/dbiir/UER-py) |
| Open source pretrained language model collection | | [github](https://github.com/ZhuiyiTechnology/pretrained-models) |
| Multilingual sentence vector package | | [github](https://github.com/yannvgn/laserembeddings) |
|Language Model as a Service (LMaaS)|Language Model as a Service|[github](https://github.com/txsun1997/LMaaS-Papers)|
|Open source language model GPT-NeoX-20B|20 billion parameters, is currently the largest publicly accessible pre-trained general autoregressive language model|[github](https://github.com/EleutherAI/gpt-neox)|
|Chinese Science Literature Dataset (CSL)|Contains 396,209 meta-information (titles, abstracts, keywords, disciplines, categories) of Chinese core journal papers. The CSL dataset can be used as a pre-training corpus, and can also be used to construct many NLP tasks, such as text summarization (title prediction), keyword generation, and text classification. |[github](https://github.com/ydli-ai/CSL)|
|Large model development artifact||[github](https://github.com/hpcaitech/ColossalAI)|

# extract

| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
| Time extraction| has been integrated into the python package [cocoNLP](https://github.com/fighting41love/cocoNLP), welcome to try| [java version](https://github.com/shinyke/Time-NLP)< br>[python version](https://github.com/zhanzecheng/Time_NLP) |
| Neural Network Relation Extraction pytorch | Chinese is not supported yet | [github](https://github.com/ShulinCao/OpenNRE-PyTorch) |
| bert-based named entity recognition pytorch | Chinese is not supported yet | [github](https://github.com/Kyubyong/bert_ner) |
| Keyphrase extraction package pke | ​​| [github](https://github.com/boudinfl/pke) |
| BLINK state-of-the-art entity link library | | [github](https://github.com/facebookresearch/BLINK) |
| Named entity recognition implemented by BERT/CRF | | [github](https://github.com/Louis-udm/NER-BERT-CRF) |
| Support batch parallel LatticeLSTM Chinese named entity recognition | | [github](https://github.com/LeeSureman/Batch_Parallel_LatticeLSTM) |
| Build a model for medical entity recognition | Contains dictionaries and corpus annotations, based on python | [github](https://github.com/yixiu00001/LSTM-CRF-medical) |
| Pipeline entity and relationship extraction based on TensorFlow and BERT| - Entity and Relation Extraction Based on TensorFlow and BERT Pipeline entity and relationship extraction based on TensorFlow and BERT, 2019 Language and Intelligence Technology Competition information extraction task solution. Schema based Knowledge Extraction, SKE 2019 | [github](https://github.com/yuanxiaosc/Entity-Relation-Extraction) |
| Chinese Named Entity Recognition NeuroNER vs BertNER | | [github](https://github.com/EOA-AILab/NER-Chinese) |
| Chinese named entity recognition based on BERT | | [github](https://github.com/lonePatient/BERT-NER-Pytorch) |
| Chinese key phrase extraction tool | | [github](https://github.com/dongrixinyu/chinese_keyphrase_extractor) |
| bert | tensorflow version for Chinese named entity recognition | [github](https://github.com/macanv/BERT-BiLSTM-CRF-NER) |
| bert-Kashgari | Kashgari, a keras-based packaging classification and labeling framework, can build a classification or sequence labeling model in a few minutes | [github](https://github.com/BrikerMan/Kashgari) |
| cocoNLP | Extraction of name, address, email address, mobile phone number, mobile phone attribution and other information, rake phrase extraction algorithm. | [github](https://github.com/fighting41love/cocoNLP)|
| Microsoft multilingual number/unit/such as date and time recognition package| | [github](https://github.com/Microsoft/Recognizers-Text)|
| Baidu open source benchmark information extraction system | | [github](https://github.com/baidu/information-extraction) |
| Chinese address word segmentation (address element recognition and extraction), NER through sequence annotation | | [github](https://github.com/yihenglu/chinese-address-segment) |
| Open-domain text knowledge triple extraction and knowledge base construction based on dependency syntax | | [github](https://github.com/lemonhu/open-entity-relation-extraction) |
| Chinese keyword extraction method based on pre-training model | | [github](https://github.com/sunyilgdx/SIFRank_zh) |
| chinese_keyphrase_extractor (CKPE) | A tool for chinese keyphrase extraction A tool for quickly extracting and identifying keyphrases from natural language texts | [github](https://github.com/dongrixinyu/chinese_keyphrase_extractor) |
| A simple resume parser to extract key information from resumes | | [github](https://github.com/OmkarPathak/pyresparser) |
| BERT Chinese NER experiments in three different modes of BERT-NER-Pytorch | | [github](https://github.com/lonePatient/BERT-NER-Pytorch) |




# Knowledge Graph

| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
| Tsinghua University XLORE Chinese-English Cross-language Encyclopedia Knowledge Graph | Baidu, Chinese Wiki, English Wiki | [link](https://xlore.org/downloadhtml) |
| Document graph automatic generation | | [github](https://github.com/liuhuanyong/TextGrapher) |
| Question answering system based on knowledge graph in the medical field | | [github](https://github.com/zhihao-chen/QASystemOnMedicalGraph) <br>This repo refers to [github](https://github.com/liuhuanyong/ QASystemOnMedicalKG) |
| Chinese Person Relation Knowledge Graph Project | | [github](https://github.com/liuhuanyong/PersonRelationKnowledgeGraph) |
| AmpliGraph Knowledge Graph Representation Learning (Python) Library Knowledge Graph Concept Link Prediction | | [github](https://github.com/Accenture/AmpliGraph) |
| Chinese knowledge graph materials, data and tools | | [github](https://github.com/husthuke/awesome-knowledge-graph) |
| Chinese knowledge map based on Baidu Encyclopedia | Extract triplet information and build Chinese knowledge map | [github](https://github.com/lixiang0/WEB_KG) |
| Zincbase Knowledge Graph Construction Toolkit | | [github](https://github.com/tomgrek/zincbase) |
| Question answering system based on knowledge graph | | [github](https://github.com/WenRichard/KBQA-BERT) |
| Knowledge graph deep learning related information | | [github](https://github.com/lihanghang/Knowledge-Graph) |
| Southeast University "Knowledge Graph" graduate course (data) | | [github](https://github.com/npubird/KnowledgeGraphCourse) |
| Knowledge Graph Cheyin Work Project | | [github](https://github.com/qiu997018209/KnowledgeGraph) |
| "One Piece" Knowledge Graph| | [github](https://github.com/mrbulb/ONEPIECE-KG) |
| A dataset of 132 knowledge graphs| covering common sense, cities, finance, agriculture, geography, weather, social networking, Internet of Things, medical care, entertainment, life, business, travel, science and education| [link](http//openkg.cn) |
| Large-scale, structured, Chinese-English bilingual COVID-19 Knowledge Graph (COKG-19) | | [link](http://www.openkg.cn/dataset?q=COKG-19) |
| Event triples extraction based on dependency syntax and semantic role annotation | | [github](https://github.com/liuhuanyong/EventTriplesExtraction) |
| Abstract Knowledge Graph| The current scale is 500,000, supporting the abstraction of nominal entities, state descriptions, and event actions | [github](https://github.com/liuhuanyong/AbstractKnowledgeGraph) |
| Large-scale Chinese knowledge graph data 1.4 billion entities | | [github](https://github.com/ownthink/KnowledgeGraphData) |
| Jiagu Natural Language Processing Tool | Based on models such as BiLSTM, it provides knowledge graph relationship extraction, Chinese word segmentation, part-of-speech tagging, named entity recognition, sentiment analysis, new word discovery, keyword text summarization, text clustering and other functions | [github](https://github .com/ownthink/Jiagu) |
| medical_NER - Chinese Medical Knowledge Graph Named Entity Recognition | | [github](https://github.com/pumpkinduo/KnowledgeGraph_NER) |
| A large list of learning materials/datasets/tool ​​resources related to knowledge graph| | [github](https://github.com/totogo/awesome-knowledge-graph) |
| LibKGE, a knowledge graph embedding library for reproducible research | | [github](https://github.com/uma-pi1/kge) |
| Question-and-answer project of knowledge map in the military field based on mongodb storage | Including 8 categories such as aircraft and space equipment, more than 100 sub-categories, a total of 5,800 items of military weapon knowledge base, this project does not use graph database for storage, and uses jieba to query Parsing, question entity item recognition, and querying of multiple types of questions based on query templates, mainly to provide a demo of the industry's question-and-answer thinking. | [github](https://github.com/liuhuanyong/QAonMilitaryKG) |
| JD Commodity Knowledge Graph | | [github](https://github.com/liuhuanyong/ProductKnowledgeGraph) |
| Chinese relation extraction based on distant supervision | | [github](https://github.com/xiaolalala/Distant-Supervised-Chinese-Relation-Extraction) |
| Intelligent Question Answering System Based on Medical Knowledge Graph | | [github](https://github.com/YeYzheng/KGQA-Based-On-medicine) |
| BLINK state-of-the-art entity link library | | [github](https://github.com/facebookresearch/BLINK) |
| A small stock knowledge graph/knowledge base | | [github](https://github.com/lemonhu/stock-knowledge-graph) |
| dstlr unstructured text scalable knowledge map construction platform | | [github](https://github.com/dstlry/dstlr) |
| Baidu Encyclopedia Character Entries Attribute Extraction | Use BERT-based fine-tuning and feature extraction methods for knowledge graphs | [github](https://github.com/sakuranew/BERT-AttributeExtraction)|
| New Coronary Pneumonia Related Data | Chinese Medical Dialogue Dataset of New Crown and Other Types of Pneumonia; Open Data Sources of Tsinghua University and Other Institutions (COVID-19) | [github](https://www.aminer.cn/data-covid19/) <br> [github](https://github.com/UCSD-AI4H/COVID-Dialogue) |
| DGL-KE Graph Embedding Representation Learning Algorithm | | [github](https://github.com/awslabs/dgl-ke) |
|CausalityEventExtraction||[method](https://github.com/liuhuanyong/CausalityEventExtraction) [data](https://github.com/fighting41love/CausalDataset)|
|Causal Event Pairs Based on Multi-Domain Text Dataset||[link](http://thuctc.thunlp.org/)|

# text generation
 
| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
| Texar | Toolkit for Text Generation and Beyond | [github](https://github.com/asyml/texar) |
|Professor Ehud Reiter's blog| | [link](https://ehudreiter.com) Strongly recommended by Professor Wan Xiaojun of Peking University, this blog has conducted in-depth discussions and reflections on NLG technology, evaluation and application. |
| A large list of text generation related resources | | [github](https://github.com/ChenChengKuan/awesome-text-generation) |
| Open Domain Dialogue Generation and Practice in Microsoft Xiaoice | Natural Language Generation Allows Machines to Master the Ability of Automatic Creation | [link](https://drive.google.com/file/d/1Mdna3q986k6OoJNsfAHznTtnMAEVzv5z/view) |
| Text Generation Control | | [github](https://github.com/harvardnlp/Talk-Latent/blob/master/mainpdf) |
| A large list of resources related to natural language generation | | [github](https://github.com/tokenmill/awesome-nlg) |
| Evaluating Natural Language Generation with BLEURT | | [link](https://ai.googleblog.com/2020/05/evaluating-natural-language-generation.html) |
| Automatic couplet data and robot| | [code link](https://github.com/wb14123/seq2seq-couplet) <br> [700,000 couplet data](https://github.com/wb14123/couplet-dataset ) |
| Automatically generate comments | Generate comments based on Hacker News article titles using the Transformer codec model | [github](https://github.com/leod/hncynic) |
| Natural language generation SQL statement (English) | | [github](https://github.com/paulfitz/mlsql) |
| Natural Language Generation Resources | | [github](https://github.com/tokenmill/awesome-nlg) |
| Chinese Generation Task Benchmark | | [github](https://github.com/CLUEbenchmark/CLGE) |
| Topic-specific text generation/text augmentation based on GPT2 | | [github](https://github.com/prakhar21/TextAugmentation-GPT2) |
| Coding, tokenizing and implementing a controllable and efficient text generation method | | [github](https://github.com/yannvgn/laserembeddings) |
| TextFooler's adversarial text generation module for text classification/reasoning | | [github](https://github.com/jind11/TextFooler) |
| SimBERT | BERT model based on UniLM idea, integrating retrieval and generation | [github](https://github.com/ZhuiyiTechnology/simbert) |
| New word generation and sentence making | Non-existent words use GPT-2 variants to generate new words, definitions, and example sentences from scratch | [github](https://github.com/turtlesoupy/this-word-does-not-exist ) |
| Multiple-choice question generation from text | | [github](https://github.com/KristiyanVachev/Question-Generation) |
| Synthetic Data Generation Benchmark | | [github](https://github.com/sdv-dev/SDGym) |
| | | |

# text summary

| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
| Chinese text summarization/keyword extraction| | [github](https://github.com/letiantian/TextRank4ZH) |
| Automatic Summarization of Resume Based on Named Entity Recognition | | [github](https://github.com/DataTurks-Engg/Entity-Recognition-In-Resumes-SpaCy) |
| Text Teaser, an automatic text summarization library | English only | [github](https://github.com/IndigoResearch/textteaser) |
| Extractive summary extraction based on the latest language models such as BERT | | [github](https://github.com/Hellisotherpeople/CX_DB8) |
| A comprehensive guide to text summarization using deep learning in Python | | [link](https://mp.weixin.qq.com/s/gDZyTbM1nw3fbEnU--y3nQ) |
| (Colab) Abstract Text Summary Implementation Highlights (Tutorial | | [github](https://github.com/theamrzaki/text_summurization_abstractive_methods) |


# Smart Q&A

| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
| Chinese chatbot | According to your own corpus, you can train the chatbot you want, which can be used in intelligent customer service, online question and answer, intelligent chat and other scenarios | [github](https://github.com/Doragd/Chinese-Chatbot- PyTorch-Implementation) |
| Interesting robot qingyun | Chinese chatbot trained by qingyun | [github](https://github.com/Doragd/Chinese-Chatbot-PyTorch-Implementation) |
| Open dialogue robots, knowledge graphs, semantic understanding, natural language processing tools and data | | [github](https://wwwownthinkcom/#header-n30) |
| qa's robot | Amodel-for-Retrivalchatbot - customer service robot, Chinese Retreival chatbot (Chinese retrieval robot) | [git](https://github.com/WenRichard/QAmodel-for-Retrievalchatbot) |
| ConvLab open source multi-domain end-to-end dialogue system platform | | [github](https://github.com/ConvLab/ConvLab) |
| A dialogue system based on the latest version of rasa | | [github](https://github.com/GaoQ1/rasa_chatbot_cn) |
| A chatbot based on the financial-judicial field (with the nature of chatting) | | [github](https://github.com/charlesXu86/Chatbot_CN) |
| End-to-End Closed Domain Dialogue System | | [github](https://github.com/cdqa-suite/cdQA) |
| MiningZhiDaoQACorpus | 5.8 million Baidu Zhizhi Q&A data mining project, Baidu Zhidao Q&A corpus, including more than 5.8 million questions, each with a question label. Based on this question and answer corpus, it can support a variety of applications, such as logic mining | [github]() |
| GPT2-chitchat, a GPT2 model for Chinese chat | | [github](https://github.com/yangjianxin1/GPT2-chitchat) |
| A list of related resources for multi-turn response selection based on retrieval chatbots (Leaderboards, Datasets, Papers) | | [github](https://github.com/JasonForJoy/Leaderboards-for-Multi-Turn-Response-Selection) |
| Microsoft Dialogue Bot Framework | | [github](https://github.com/microsoft/botframework) |
| chatbot-list | In the industry about intelligent customer service, chatbot application and architecture, algorithm sharing and introduction | [github](https://github.com/lizhe2004/chatbot-list) |
| Chinese medical dialogue data Chinese medical dialogue data set | | [github](https://github.com/Toyhom/Chinese-medical-dialogue-data) |
| A large-scale medical dialogue dataset | Contains 1.1 million medical consultations and 4 million doctor-patient dialogues | [github](https://github.com/UCSD-AI4H/Medical-Dialogue-System) |
| Large-scale cross-domain Chinese task-oriented multi-round dialogue dataset and model CrossWOZ | | [paper & data](https://arxiv.org/pdf/200211893pdf) |
| Open source conversational information search platform | | [github](https://github.com/microsoft/macaw) |
| Contextual Interaction Multimodal Dialogue Challenge 2020 (DSTC9 2020) | | [github](https://github.com/facebookresearch/simmc) |
| Paraphrase of T5 questions trained with Quora questions (Paraphrase) | | [github](https://github.com/renatoviolin/T5-paraphrase-generation) |
| Google releases Taskmaster-2 natural language task dialogue dataset | | [github](https://github.com/google-research-datasets/Taskmaster/tree/master/TM-2-2020) |
| Haystack is a flexible, powerful and extensible question answering (QA) framework | | [github](https://github.com/deepset-ai/haystack) |
| End-to-End Closed Domain Dialogue System | | [github](https://github.com/cdqa-suite/cdQA) |
| Amazon releases knowledge-based human-human open domain dialogue dataset | | [github](https://github.com/alexa/alexa-prize-topical-chat-dataset/) |
| Albert Large QA model trained based on Baidu webqa and dureader dataset | | [github](https://github.com/wptoux/albert-chinese-large-webqa/tree/master) |
| CommonsenseQA English QA challenge for common sense| | [link](https://www.tau-nlp.org/commonsenseqa) |
| MedQuAD (English) Medical Question Answering Dataset | | [github](https://github.com/abachaa/MedQuAD) |
| Based on Albert and Electra, a question answering engine using Wikipedia text as context | | [github](https://github.com/renatoviolin/Question-Answering-Albert-Electra) |
| A question-and-answer attempt based on the 14W song knowledge base| Functions include Lyrics Solitaire, known lyrics to find songs, and question-and-answer questions about the triangular relationship between song singers and singers| [github](https://github.com/liuhuanyong/MusicLyricChatbot) |


# text error correction

| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
| Chinese text error correction module code | | [github](https://github.com/zedom1/error-detection) |
| English spell check library | | [github](https://github.com/barrust/pyspellchecker) |
| python spell checker library | | [github](https://github.com/barrust/pyspellchecker) |
| GitHub Typo Corpus Large-Scale GitHub Multilingual Spelling/Grammar Error Dataset | | [github](https://github.com/mhagiwara/github-typo-corpus) |
| BertPunc BERT-based state-of-the-art punctuation repair model | | [github](https://github.com/nkrnrnk/BertPunc) |
| Chinese writing proofreading tool| | [github](https://xiezuocat.com/#/) |
|Text Error Correction Literature List| Chinese Spell Checking (CSC) and Grammatical Error Correction (GEC)|[github](https://github.com/nghuyong/text-correction-papers)|
|The champion scheme of text intelligent proofreading competition|has been implemented, from the team of Soochow University and Bodhidharma Academy|[link](https://mp.weixin.qq.com/s/2TjpmoYnt2BUTQVLi26AFA)|


# Multimodal
| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
|Chinese multimodal data set "Wukong"|Huawei Noah's Ark Laboratory is a large-scale open source, containing 100 million image-text pairs|[github](https://wukong-dataset.github.io/wukong-dataset/)|
|Chinese graphic representation pre-training model Chinese-CLIP|Chinese version CLIP pre-training model, open source multiple model scales, a few lines of code to get Chinese graphic representation extraction & graphic retrieval|[github](https://github.com /OFA-Sys/Chinese-CLIP)|


# speech processing

| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
| ASR Speech Dataset + Chinese Speech Recognition System Based on Deep Learning | | [github](https://github.com/nl8590687/ASRT_SpeechRecognition) |
| Tsinghua University THCHS30 Chinese Speech Data Set| data_thchs30tgz>) <br>[test-noisetgz-OpenSLR domestic mirror](<http//cn-mirroropenslrorg/resources/18/test-noisetgz>)[test-noisetgz](<http//wwwopenslrorg/resources/18/test -noisetgz>) <br>[resourcetgz-OpenSLR domestic mirror](<http//cn-mirroropenslrorg/resources/18/resourcetgz>)<br>[resourcetgz](<http//wwwopenslrorg/resources/18/resourcetgz>) <br>[Free ST Chinese Mandarin Corpus](<http//cn-mirroropenslrorg/resources/38/ST-CMDS-20170001_1-OSargz>)<br>[Free ST Chinese Mandarin Corpus](<http//wwwopenslrorg/resources /38/ST-CMDS-20170001_1-OSargz>)<br>[AIShell-1 open source version data set-OpenSLR domestic image](<http//cn-mirroropenslrorg/resources/33/data_aishelltgz>)<br>[AIShell-1 open source version data set](<http//wwwopenslrorg/resources/33/data_aishelltgz>)<br>[Primewords Chinese Corpus Set 1- OpenSLR Domestic Mirror](<http//cn-mirroropenslrorg/resources/47/primewords_md_2018_set1targz>)<br>[Primewords Chinese Corpus Set 1](<http//wwwopenslrorg/resources/47/primewords_md_2018_set1targz>) |
| Laughter Detector | | [github](https://github.com/ideo/LaughDetection) |
| New version of Common Voice Speech Recognition Dataset | Including more than 1,400 hours of speech samples from 42,000 contributors, covered by github | [link](https://voice.mozilla.org/en/datasets) |
| speech-aligner | A tool for generating phoneme-level temporal alignment annotations from "human voice speech" and its "language text" | [github](https://github.com/open-speech/speech-aligner) |
| ASR Speech Dictionary/Dictionary| | [github](hhttps://github.com/aishell-foundation/DaCiDian) |
| Speech Emotion Analysis | | [github](https://github.com/MITESHPUTHRANNEU/Speech-Emotion-Analyzer) |
| masr | Chinese speech recognition, providing pre-trained models, high recognition rate | [github](https://github.com/lukhy/masr) |
| Chinese text normalization for speech recognition | | [github](https://github.com/speech-io/chinese_text_normalization) |
| Speech Quality Evaluation Indicators (MOSNet, BSSEval, STOI, PESQ, SRMR) | | [github](https://github.com/aliutkus/speechmetrics) |
| Chinese/English Pronunciation Dictionary for Speech Recognition| | [github](https://github.com/speech-io/BigCiDian) |
| Multilingual speech-to-text translation corpus released by CoVoSTEFacebook| Includes speech and text in 11 languages ​​(French, German, Dutch, Russian, Spanish, Italian, Turkish, Persian, Swedish, Mongolian and Chinese) Transcription and English translation | [github](https://github.com/facebookresearch/covost) |
| Parakeet text-to-speech synthesis based on PaddlePaddle | | [github](https://github.com/PaddlePaddle/Parakeet) |
| (Java) Accurate speech natural language detection library | | [github](https://github.com/pemistahl/lingua) |
| Multilingual speech-text translation corpus released by CoVoSTEFacebook | | [github](https://github.com/facebookresearch/covost) |
| Text-to-speech synthesis implemented by TensorFlow 2 | | [github](https://github.com/as-ideas/TransformerTTS) |
| Python audio feature extraction package | | [github](https://github.com/novoic/surfboard) |
| ViSQOL audio quality perception is objective and complete reference index, divided into two modes: audio and voice | | [github](https://github.com/google/visqol) |
| zhrtvc | An easy-to-use Chinese speech clone and Chinese speech synthesis system | [github](https://github.com/KuangDD/zhrtvc) |
| aukit | A useful speech processing toolbox, including speech noise reduction, audio format conversion, feature spectrum generation and other modules | [github](https://github.com/KuangDD/aukit) |
| phkit | An easy-to-use phoneme processing toolbox, including Chinese phonemes, English phonemes, text-to-pinyin, text regularization and other modules | [github](https://github.com/KuangDD/phkit) |
| zhvoice | Chinese speech corpus, the speech is clearer and more natural, including 8 open source data sets, 3200 speakers, 900 hours of speech, 13 million words | [github](https://github.com/KuangDD/zhvoice) |
| audio is an audio annotation tool for speech behavior detection, binarization, speaker recognition, automatic speech recognition, emotion recognition, etc. | [github](https://github.com/midas-research/audino) |
| Deep Learning Emotional Text-to-Speech Synthesis | | [github](https://github.com/Emotional-Text-to-Speech/dl-for-emo-tts) |
| Python audio data augmentation library | | [github](https://github.com/iver56/audiomentations) |
| Audio enhancement based on large-scale audio dataset Audioset | | [github](https://github.com/AppleHolic/audioset_augmentor) |
| Voice Migration| | [github](https://github.com/fighting41love/become-yukarin) |



# document processing

| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
|LayoutLM-v3 document understanding model||[github](https://github.com/microsoft/unilm/tree/master/layoutlmv3)|
| PyLaia Deep Learning Toolkit for Handwritten Document Analysis | | [github](https://github.com/jpuigcerver/PyLaia) |
| Single document unsupervised keyword extraction | | [github](https://github.com/LIAAD/yake) |
| DocSearch free document search engine | | [github](https://github.com/algolia/docsearch) |
| fdfgen | Can automatically create pdf documents and fill in information | [link](https://github.com/ccnmtl/fdfgen) |
| pdfx | Automatically extract cited references and download the corresponding pdf file | [link](https://github.com/metachris/pdfx) |
| invoice2data | Invoice pdf information extraction | [invoice2data](https://github.com/invoice-x/invoice2data) |
| PDF document information extraction | | [github](https://github.com/jstockwin/py-pdf-parser) |
|PDFMiner | PDFMiner can get the exact position of the text in the page, and other information such as font or line. It also has a PDF converter that can convert PDF files to other text formats such as HTML. There is also an extensible parser PDF that can be used for other purposes than text analysis. | [link](https://github.com/euske/pdfminer) |
| PyPDF2 | PyPDF 2 is a python PDF library capable of splitting, merging, cropping and converting pages of PDF files. It can also add custom data, viewing options and passwords to PDF files. It can retrieve text and metadata from PDFs, and can also merge entire files together. | [link](https://github.com/mstamy2/PyPDF2) |
| PyPDF2 | PyPDF 2 is a python PDF library capable of splitting, merging, cropping and converting pages of PDF files. It can also add custom data, viewing options and passwords to PDF files. It can retrieve text and metadata from PDFs, and can also merge entire files together. | [link](https://github.com/mstamy2/PyPDF2) |
| ReportLab | ReportLab can quickly create PDF documents. A time-proven, super-easy-to-use open source project for creating complex, data-driven PDF documents and custom vector graphics. It's free, open source, and written in Python. With more than 50,000 downloads per month, the package is part of standard Linux distributions, embedded in many products, and was chosen to power Wikipedia's print/export functionality. | [link](https://www.reportlab.com/opensource/) |
| Simple PDF file text editor written by SIMPdfPython | | [github](https://github.com/shashanoid/Simpdf) |
|pdf-diff |PDF file diff tool can display the difference between two pdf documents| [github](https://github.com/serhack/pdf-diff)|


# form processing

| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
| Use unet to realize automatic detection and table reconstruction of document tables | | [github](https://github.com/chineseocr/table-ocr) |
| pdftabextract | Used for form information analysis after OCR recognition, very powerful | [link](https://github.com/WZBSocialScienceCenter/pdftabextract) |
| tabula-py | Directly convert the table information in pdf to pandas dataframe, with java and python version codes | [](https://github.com/chezou/tabula-py) |
| camelot | pdf form analysis | [link](https://github.com/atlanhq/camelot) |
| pdfplumber | pdf table analysis | [](https://github.com/jsvine/pdfplumber) |
| PubLayNet | Able to divide paragraphs, identify tables, pictures | [link](https://github.com/ibm-aur-nlp/PubTabNet) |
| Extract tabular data from papers | | [github](https://github.com/paperswithcode/axcell) |
| Finding answers in tables with BERT | | [github](https://github.com/google-research/tapas) |
| 表格问答的系列文章| | [简介](https://mp.weixin.qq.com/s?__biz=MzAxMDk0OTI3Ng==&mid=2247484103&idx=2&sn=4a5b50557ab9178270866d812bcfc87f&chksm=9b49c534ac3e4c22de7c53ae5d986fac60a7641c0c072d4038d9d4efd6beb24a22df9f859d08&scene=21#wechat_redirect)<br>[模型](https://mp.weixin.qq.com/s?__biz=MzAxMDk0OTI3Ng==&mid=2247484103&idx=1&sn=73f37fbc1dbd5fdc2d4ad54f58693ef3&chksm=9b49c534ac3e4c222f6a320674b3728cf8567b9a16e6d66b8fdcf06703b05a16a9c9ed9d79a3&scene=21#wechat_redirect)<br>[完结篇](https://mp.weixin .qq.com/s/ee1DG_vO2qblqFC6zO97pA) |
| Use GAN to generate tabular data (English only) | | [github](https://github.com/Diyago/GAN-for-tabular-data) |
| carefree-learn (PyTorch) | AutoML package for tabular datasets | [github](https://github.com/carefree0910/carefree-learn) |
| Closed domain fine-tuning table detection | | [github](https://github.com/holms-ur/fine-tuning) |
| PDF table data extraction tool | | [github](https://github.com/camelot-dev/camelot) |
| TaBERT理解表格数据查询的新模型| | [paper](https://scontent-hkt1-1xxfbcdnnet/v/t398562-6/106708899_597765107810230_1899215558892880563_npdf?_nc_cat=107&_nc_sid=ae5e01&_nc_ohc=4sN3TJwewSIAX8iliBD&_nc_ht=scontent-hkt1-1xx&oh=eccb9795f027ff63be61ff4a5e337c02&oe=5F316505 ) |
| Table Processing | Awesome-Table-Recognition | [github](https://github.com/cv-small-snails/Awesome-Table-Recognition)|



# text match

| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
| Sentence, QA similarity matching MatchZoo | A collection of text similarity matching algorithms, including multiple deep learning methods, worth trying. | [github](https://github.com/NTMC-Community/MatchZoo) |
| Chinese sentence similarity calculation competition and scheme summary | | [github](https://github.com/ShuaichiLi/Chinese-sentence-similarity-task) |
| similarity similarity calculation toolkit | written in java, used for similarity calculations related to words, phrases, sentences, lexical analysis, sentiment analysis, semantic analysis, etc. | [github](https://github.com/shibing624/similarity) |
| Chinese Word Similarity Calculation Method | Combined with the word similarity calculation method of Synonyms Cilin Extended Edition and Hownet (Hownet), the vocabulary coverage is more and the result is more accurate. | [gihtub](https://github.com/yaleimeng/Final_word_Similarity) |
| Python string similarity algorithm library | | [github](https://github.com/luozhouyang/python-string-similarity) |
| A similar sentence judgment model based on the Siamese bilstm model, providing training data sets and test data sets | Provides 100,000 training samples | [github](https://github.com/liuhuanyong/SiameseSentenceSimilarity) |


# text data augmentation

| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
| Chinese NLP data enhancement (EDA) tool | | [github](https://github.com/zhanlaoban/eda_nlp_for_Chinese) |
| English NLP data enhancement tool | | [github](https://github.com/makcedward/nlpaug) |
| One-click Chinese data enhancement tool | | [github](https://github.com/425776024/nlpcda) |
| The application and effect of data augmentation in machine translation and other nlp tasks | | [link](https://mp.weixin.qq.com/s/_aVwSWuYho_7MUT0LuFgVA) |
| NLP data augmentation resource set | | [github](https://github.com/quincyliang/nlp-data-augmentation) |


# Common regular expressions

| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
| Regular expression for extracting emails| | Has been integrated into the python package [cocoNLP](https://github.com/fighting41love/cocoNLP), welcome to try |
| Extract phone_number | | Has been integrated into the python package [cocoNLP](https://github.com/fighting41love/cocoNLP), welcome to try |
| Regular expression for extracting ID number | IDCards_pattern = r'^([1-9]\d{5}[12]\d{3}(0[1-9]\|1[012])(0 [1-9]\|[12][0-9]\|3[01])\d{3}[0-9xX])<br>IDs = re.findall(IDCards_pattern, text, flags=0) |
IP address regular expression |(25[0-5]\| 2[0-4]\d\| [0-1]\d{2}\| [1-9]?\d)\.(25 [0-5]\| 2[0-4]\d\| [0-1]\d{2}\| [1-9]?\d)\.(25[0-5]\| 2 [0-4]\d\| [0-1]\d{2}\| [1-9]?\d)\.(25[0-5]\| 2[0-4]\d\ | [0-1]\d{2}\| [1-9]?\d)||
| Tencent QQ regular expression | \[1-9]([0-9]{5,11}) | |
| Domestic fixed-line number regular expression | [0-9-()()]{7,18} | |
| Username regular expression | [A-Za-z0-9_\-\u4e00-\u9fa5]+ | |
| Regular matching of domestic phone numbers (three major operators + virtual, etc.) | | [github](https://github.com/VincentSit/ChinaMobilePhoneNumberRegex) |
| Regular Expression Tutorial | | [github](https://github.com/ziishaned/learn-regex/blob/master/translations/README-cnmd) |


# text search

| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
| Efficient fuzzy search tool | | [github](https://github.com/Yggdroot/LeaderF) |
| Large list/search engine of BERT models for various languages/tasks| | [link](https://bertlang.unibocconi.it/) |
| Deepmatch's deep matching model library for recommendation, advertising and search | | [github](https://github.com/shenweichen/DeepMatch) |
| wwsearch is a full-text search engine developed by the enterprise WeChat background | | [github](https://github.com/Tencent/wwsearch) |
| aili - the fastest in-memory index in the East The fastest concurrent index in the East | | [github](https://github.com/UncP/aili) |
|Efficient string matching tool RapidFuzz|a fast string matching library for Python and C++, which is using the string similarity calculations from FuzzyWuzzy|[github](https://github.com/maxbachmann/rapidfuzz)|

# reading comprehension

| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
| Efficient fuzzy search tool | | [github](https://github.com/Yggdroot/LeaderF) |
| Large list/search engine of BERT models for various languages/tasks| | [link](https://bertlang.uniboc.coni.it) |
| Deepmatch's deep matching model library for recommendation, advertising and search | | [github](https://github.com/shenweichen/DeepMatch) |
| allennlp reading comprehension supports multiple data and models | | [github](https://github.com/allenai/allennlp-reading-comprehension) |



# emotion analysis

| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
| Aspect Based Sentiment Analysis Package | | [github](https://github.com/ScalaConsultants/Aspect-Based-Sentiment-Analysis) |
| awesome-nlp-sentiment-analysis | Sentiment analysis, emotion cause identification, evaluation object and evaluation word extraction | [github](https://github.com/haiker2011/awesome-nlp-sentiment-analysis) |
| Emotional analysis technology enables intelligent customer service to understand human emotions | | [github](https://developeraliyuncom/article/761513?utm_content=g_1000124809) |


# Event extraction

| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
| Chinese event extraction| | [github](https://github.com/liuhuanyong/ComplexEventExtraction) |
| NLP event extraction literature resource list | | [github](https://github.com/BaptisteBlouin/EventExtractionPapers) |
| BERT event extraction implemented by PyTorch (ACE 2005 corpus) | | [github](https://github.com/nlpcl-lab/bert-event-extraction) |
| News event clue extraction| | [github](https://github.com/liuhuanyong/ImportantEventExtractor) |


# machine translation

| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
| Wudao Dictionary| The command-line version of Youdao Dictionary, supports English-Chinese mutual search and online query| [github](https://github.com/ChestnutHeng/Wudao-dict) |
|NLLB|A language model NLLB that supports arbitrary inter-translation of 200+ languages|[link](https://openbmb.github.io/BMList/list/)|
|Easy-Translate|Script to translate large text files locally, based on Facebook/Meta AI's M2M100 model and NLLB200 model, supports 200+ languages|[github](https://github.com/ikergarcia1996/Easy-Translate/ fork)|

# Number conversion

| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
| The best Chinese character number (Chinese number)-Arabic number conversion tool | | [github](https://github.com/Wall-ee/chinese2digits) |
| Quickly convert "Chinese numbers" and "Arabic numbers" | | [github](https://github.com/HaveTwoBrush/cn2an) |
| Parse and convert natural language numeric strings into integers and floating point numbers | | [github](https://github.com/jaidevd/numerizer) |


# Referencing resolution

| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
| Chinese reference to digestion data| | [github](https://github.com/CLUEbenchmark/CLUEWSC2020) <br>[baidu ink](https://pan.baidu.com/s/1gKP_Mj-7KVfFWpjYvSvAAA) code a0qq |


# text clustering

| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
| TextCluster short text clustering preprocessing module Short text cluster | | [github](https://github.com/RandyPen/TextCluster) |


# Text Categorization


| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
| NeuralNLP-NeuralClassifier Tencent open source deep learning text classification tool | | [github](https://github.com/Tencent/NeuralNLP-NeuralClassifier) ​​|


# knowledge reasoning

| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
| GraphbrainAI open source software library and scientific research tools to facilitate automatic meaning extraction and text understanding as well as knowledge exploration and inference | | [github](https://github.com/graphbrain/graphbrain) |
| (Harvard) Free Book on Causal Reasoning | | [pdf](https://cdn1sphharvardedu/wp-content/uploads/sites/1268/2019/10/ci_hernanrobins_23oct19pdf) |

# Interpretable natural language processing

| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
| State-of-the-art interpreter library for text machine learning models | | [github](https://github.com/interpretml/interpret-text) |


# text attack

| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
| TextAttack natural language processing model adversarial attack framework | | [github](https://github.com/QData/TextAttack) |
|OpenBackdoor: Text backdoor attack and defense toolkit| OpenBackdoor is developed based on Python and PyTorch, which can be used to reproduce, evaluate and develop related algorithms for text backdoor attack and defense| [github](https://github.com/thunlp/OpenBackdoor)|

# text visualization

| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
| Scattertext text visualization (python) | | [github](https://github.com/JasonKessler/scattertext) |
| whatlies word vector interactive visualization | | [spacy tool](https://spacyio/universe/project/whatlies) |
| PySS3 Machine Visualization Tool for SS3 Text Classifiers for Explainable AI | | [github](https://github.com/sergioburdisso/pyss3) |
| Render 3D images with notepad | | [github](https://github.com/khalladay/render-with-notepad) |
| Attention interactive visualization of transformer language models such as attnvisGPT2 and BERT | | [github](https://github.com/SIDN-IAP/attnvis) |
| Texthero text data processing package | Including preprocessing, keyword extraction, named entity recognition, vector space analysis, text visualization, etc. | [github](https://github.com/jbesomi/texthero) |

# Text annotation tool

| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
| Overview of NLP annotation platform | | [github](https://github.com/alvations/annotate-questionnaire) |
| brat rapid annotation tool sequence annotation tool | | [link](http://brat.nlplab.org/index.html) |
| Poplar web version natural language annotation tool | | [github](https://github.com/synyi/poplar) |
| LIDA lightweight interactive dialogue annotation tool | | [github](https://github.com/Wluper/lida) |
| doccano is a web-based open source collaborative multilingual text annotation tool | | [github](https://github.com/doccano/doccano) |
| Datasaurai online data labeling workflow management tool | | [link](https://datasaurai.gitbook.io/datasaur/) |

# language detection

| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
| langid | 97 languages ​​detected | [https://github.com/saffsd/langid.py](https://github.com/saffsd/langid.py) |
| langdetect | Language Detection | [https://code.google.com/archive/p/language-detection/](https://code.google.com/archive/p/language-detection/) |

# Comprehensive tools

| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
| jieba | | [jieba](https://github.com/fxsjy/jieba) |
| hanlp | | [hanlp](https://github.com/hankcs/pyhanlp) |
| nlp4han | Chinese natural language processing tool set (sentence segmentation/word segmentation/part-of-speech tagging/chunking/syntactic analysis/semantic analysis/NER/N-gram/HMM/pronoun resolution/sentiment analysis/spelling check| [github](https:/ /github.com/kidden/nlp4han) |
| Advances in Hate Speech Detection | | [link](https://ai.facebook.com/blog/ai-advances-to-better-detect-hate-speech) |
| Pytorch-based Bert application | Including named entity recognition, sentiment analysis, text classification and text similarity, etc. | [github](https://github.com/rsanshierli/EasyBert) |
| nlp4han Chinese Natural Language Processing Toolset | Sentence/word segmentation/part-of-speech tagging/chunking/syntactic analysis/semantic analysis/NER/N-gram/HMM/pronoun resolution/sentiment analysis/spelling check| [github](https:// github.com/kidden/nlp4han) |
| Some basic models of natural language | | [github](https://github.com/lpty/nlp_base) |
| Template code for sequence labeling and text classification with BERT | | [github](https://github.com/yuanxiaosc/BERT-for-Sequence-Labeling-and-Text-Classification)|
| jieba_fast accelerated version of jieba | | [github](https://github.com/deepcs233/jieba_fast) |
| StanfordNLP | Pure Python Natural Language Processing Package | [link](https://stanford.nlp.github.io/stanfordnlp/) |
| Python Spoken Natural Language Processing Toolset (English) | | [github](https://github.com/gooofy/py-nltools) |
| PreNLP natural language preprocessing library | | [github](https://github.com/lyeoni/prenlp) |
|Some papers and codes related to nlp| Including topic model, word vector (Word Embedding), named entity recognition (NER), text classification (Text Classificatin), text generation (Text Generation), text similarity (Text Similarity) calculation, etc. , involving various nlp-related algorithms, based on keras and tensorflow | [github](https://github.com/msgi/nlp-journey) |
| Python text mining/NLP practical example | | [github](https://github.com/kavgan/nlp-in-practice) |
| Forte's flexible and powerful natural language processing pipeline tool set | | [github](https://github.com/asyml/forte) |
| stanza Stanford team NLP tool | Can handle more than 60 languages ​​| [github](https://github.com/stanfordnlp/stanza) |
| Fancy-NLP is a text knowledge mining tool for building product portraits | | [github](https://github.com/boat-group/fancy-nlp) |
| A comprehensive and simple Chinese NLP toolkit | | [github](https://github.com/dongrixinyu/JioNLP) |
| Recurrence of vectorized recall pipeline based on DSSM commonly used in the industry | | [github](https://github.com/wangzhegeek/DSSM-Lookalike) |
| Texthero text data processing package | Including preprocessing, keyword extraction, named entity recognition, vector space analysis, text visualization, etc. | [github](https://github.com/jbesomi/texthero) |
| nlpgnn Graph Neural Network Natural Language Processing Toolbox | | [github](https://github.com/kyzhouhzau/NLPGNN) |
| Macadam | Based on Tensorflow (Keras) and bert4keras, a natural language processing toolkit focusing on text classification, sequence labeling and relation extraction | [github](https://github.com/yongzhuo/Macadam) |
| LineFlow is an efficient NLP data loader for all deep learning frameworks | | [github](https://github.com/tofunlp/lineflow) |
|Arabica: Python Text Data Exploratory Analysis Toolkit||[github](https://github.com/PetrKorab/Arabica)|
|Python stress testing tool: SMSBoom||[github](github.com/WhaleFell/SMSBoom)|

# Funny tool

| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
| Wangfeng Lyric Generator| | [phunterlau/wangfeng-rnn](https://github.com/phunterlau/wangfeng-rnn) |
| Girlfriend emotional fluctuation analysis | | [github](https://github.com/CasterWx/python-girlfriend-mood/) |
| NLP is too hard series | | [github](https://github.com/fighting41love/hardNLP) |
| Variable naming artifact | | [github](https://github.com/unbug/codelf) [link](https://unbug.github.io/codelf/) |
| Image text removal, can be used for comic translation | | [github](https://github.com/yu45020/Text_Segmentation_Image_Inpainting) |
| CoupletAI - couplet generation | Automatic couplet system based on CNN+Bi-LSTM+Attention| [github](https://github.com/WiseDoge/CoupletAI) |
| Using neural network symbolic reasoning to solve complex mathematical equations | | [github](https://ai.facebook.com/blog/using-neural-networks-to-solve-advanced-mathematics-equations/) |
| A question-and-answer robot based on the 14W song knowledge base | Features include Lyrics Solitaire, search for songs with known lyrics, and question-and-answer questions about the triangular relationship between singers and singers | [github](https://github.com/liuhuanyong/MusicLyricChatbot) |
| COPE - Metric Poetry Editing Program | | [github](https://github.com/LingDong-/cope) |
|Paper2GUI | An AI desktop APP toolbox for ordinary people. It can be used immediately without installation. It already supports 18+ AI models, and the content covers speech synthesis, video frame complement, video super resolution, target detection, image stylization, OCR Recognition and other fields | [github](https://github.com/Baiyuetribe/paper2gui) |
|Politeness estimator (training using Sina Weibo data)|| [github](https://github.com/tslmy/politeness-estimator) [paper](https://dl.acm.org/doi/abs /10.1145/3415190)|
|Grasspy (Python Chinese Version) Getting Started Guide|Chinese Programming Language|[homepage](https://www.grasspy.cn/zwdocs/grasspy-start/day1/) [gitee](https://gitee.com/ laowu2019_admin/zwdocs)|



# course report interview, etc.

| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
| Natural Language Processing Report| | [link](https://static.aminer.cn/misc/article/nlppdf) |
| Knowledge Graph Report| | [link](https://www.aminer.cn/research_report/5c3d5a8709%20e961951592a49d?download=true&pathname=knowledgegraphpdf) |
| Data Mining Report | | [link](https://www.aminer.cn/research_report/5c3d5a5cecb160952fa10b76?download=true&pathname=dataminingpdf) |
| Autonomous Driving Report| | [link](https://static.aminer.cn/misc/article/selfdrivingpdf) |
| Machine Translation Report| | [link](https://static.aminer.cn/misc/article/translationpdf) |
| Blockchain Report| | [link](https://static.aminer.cn/misc/article/blockchain_publicpdf) |
| Robotics Report| | [link](https://static.aminer.cn/misc/article/robotics_betapdf) |
| Computer Graphics Report| | [link](https://static.aminer.cn/misc/article/cgpdf) |
| 3D Printing Report| | [link](https://static.aminer.cn/misc/article/3dpdf) |
| Face Recognition Report| | [link](https://static.aminer.cn/misc/article/facerecognitionpdf) |
| Artificial Intelligence Chip Report | | [link](https://static.aminer.cn/misc/article/aichippdf) |
| cs224n Deep Learning Natural Language Processing Course| | [link](http//web.stanford.edu/class/cs224n/) pytorch implementation of the model in the course[link](https://github.com/DSKSD/DeepNLP- models-Pytorch) |
| NLP Tutorial by Example for Deep Learning Researchers | | [github](https://github.com/graykode/nlp-tutorial) |
| "Natural Language Processing" by Jacob Eisenstein | | [github](https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notespdf) |
| ML-NLP | Machine Learning (Machine Learning), knowledge points and code implementation often tested in NLP interviews | [github](https://github.com/NLP-LOVE/ML-NLP) |
| NLP task example project code set | | [github](https://github.com/explosion/projects) |
| Review of NLP highlights in 2019 | | [download](https://pan.baidu.com/s/1h5gEPUhvY1HkUVc32eeX4w) |
| nlp-recipes produced by Microsoft - Best Practices and Examples of Natural Language Processing | | [github](https://github.com/microsoft/nlp-recipes) |
| NLP Tutorial by Example for Deep Learning Researchers | | [github](https://github.com/graykode/nlp-tutorial) |
| Transfer Learning in Natural Language Processing (NLP) | | [youtube](https://www.youtube.com/watch?v=ly0TRNr7I_M) |
|"Machine Learning System" book| | [link](https://openmlsys.github.io/) [github](https://github.com/fighting41love/openmlsys-zh) |


# Contest

| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
| Review the TOP solutions of all NLP competitions | | [github](https://github.com/zhpmatrix/nlp-competitions-list-review) |
| 2019 Baidu Triplet Extraction Competition, "Scientific Space Team" source code (7th place) | | [github](https://github.com/bojone/kg-2019) |


# Financial natural language processing

| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
| BDCI2019 Financial Negative Information Judgment| | [github](https://github.com/A-Rain/BDCI2019-Negative_Finance_Info_Judge) |
| Open source financial investment data extraction tool | | [github](https://github.com/PKUJohnson/OpenData) |
| A large list of natural language processing research resources in the financial field | | [github](https://github.com/icoxfog417/awesome-financial-nlp) |
| A chatbot based on the financial-judicial field (with the nature of chatting) | | [github](https://github.com/charlesXu86/Chatbot_CN) |
|Small financial knowledge graph construction process demonstration| |[github](github.com/jm199504/Financial-Knowledge-Graphs)|

# Medical Natural Language Processing

| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
| Arrangement of Chinese medical NLP public resources | | [github](https://github.com/GanjinZero/awesome_Chinese_medical_NLP) |
| spaCy medical text mining and information extraction | | [github](https://github.com/NLPatVCU/medaCy) |
| Build a model for medical entity recognition | Contains dictionaries and corpus annotations, based on python | [github](https://github.com/yixiu00001/LSTM-CRF-medical) |
| A question answering system based on knowledge graphs in the medical field | | [github](https://github.com/zhihao-chen/QASystemOnMedicalGraph) This repo refers to [github](https://github.com/liuhuanyong/QASystemOnMedicalKG) |
| Chinese medical dialogue data Chinese medical dialogue data set | | [github](https://github.com/Toyhom/Chinese-medical-dialogue-data) |
| A large-scale medical dialogue dataset | Contains 1.1 million medical consultations and 4 million doctor-patient dialogues | [github](https://github.com/UCSD-AI4H/Medical-Dialogue-System) |
| New Coronary Pneumonia Related Data | Chinese Medical Dialogue Dataset of New Crown and Other Types of Pneumonia; Open Data Sources of Tsinghua University and Other Institutions (COVID-19) | [github](https://www.aminer.cn/data-covid19/) <br> [github](https://github.com/UCSD-AI4H/COVID-Dialogue) |


# Legal Natural Language Processing

| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
| Blackstone's spaCy pipeline and NLP models for unstructured legal text | | [github](https://github.com/ICLRandD/Blackstone) |
| List of legal intelligence literature resources | | [github](https://github.com/thunlp/LegalPapers) |
| A chatbot based on the financial-judicial field (with the nature of chatting) | | [github](https://github.com/charlesXu86/Chatbot_CN) |
| Crime legal terms and classification model| Contains 856 crime knowledge graphs, crime prediction based on 2.8 million crime training database, 13 types of question classification and legal information question and answer function based on 20W legal question and answer pairs| [github](https://github .com/liuhuanyong/CrimeKgAssitant) |

# Generate image from text

| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
| Dalle-mini|A mini version of DALL·E that generates pictures according to text prompts|[github](https://github.com/borisdayma/dalle-mini)|

# other

| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
| phone | Chinese mobile phone attribution query | [ls0f/phone](https://github.com/ls0f/phone) |
| phone | International mobile phone, telephone attribution inquiry | [AfterShip/phone](https://github.com/AfterShip/phone) |
| ngender | Judging gender by name | [observerss/ngender](https://github.com/observerss/ngender) |
| Summary of the difference between Chinese and English natural language processing NLP | | [link](https://mp.weixin.qq.com/s/LQU_HJ4q74lL5oCIk7w5RA) |
| Technical documents PDF or PPT shared by Daniel in major companies | | [github](https://github.com/0voice/from_coder_to_expert) |
| comparxiv A command for comparing the differences between two submitted versions on arXiv | | [pypi](https://pypiorg/project/comparxiv/) |
| Meta-architecture of CHAMELEON deep learning news recommendation system | | [github](https://github.com/gabrielspmoreira/chameleon_recsys) |
| Automated Resume Screening System | | [github](https://github.com/JAIJANYANI/Automated-Resume-Screening-System) |
| A variety of text readability evaluation indicators implemented by Python | | [github](https://github.com/cdimascio/py-readability-metrics) |




<!-- # Remarks

Pretrain Chinese Model based on confrontational learning, albert-chinese-ner - Chinese NER with pre-trained language model ALBERT, topic-specific text generation/text augmentation based on GPT2, open source pre-trained language model collection, multilingual sentence vector package, encoding, Marking and implementation: a controllable and efficient text generation method, a large list of English swear words, attnvis: GPT2, BERT and other transformer language model attention interaction visualization, CoVoST: a multilingual speech-to-text translation corpus released by Facebook, including 11 languages (French, German, Dutch, Russian, Spanish, Italian, Turkish, Persian, Swedish, Mongolian and Chinese) speech, text transcription and English translation, Jiagu natural language processing tools - based on models such as BiLSTM Foundation, providing functions such as knowledge map relation extraction, Chinese word segmentation, part-of-speech tagging, named entity recognition, sentiment analysis, new word discovery, keyword text summarization, text clustering, automatic detection of document tables, table reconstruction, NLP event extraction, document resource list, finance Large list of natural language processing research resources in the field, CLUEDatasetSearch - Chinese and English NLP datasets: Search all Chinese NLP datasets, with commonly used English NLP datasets, medical_NER - Chinese medical knowledge graph named entity recognition, (Harvard) free book on causal reasoning , A large list of learning materials/datasets/tool ​​resources related to knowledge graphs, Forte: a flexible and powerful natural language processing pipeline tool set, Python string similarity algorithm library, PyLaia: a deep learning toolkit for handwritten document analysis, TextFooler: for Adversarial text generation module for text classification/reasoning, Haystack: a flexible and powerful scalable Question Answering (QA) framework, Chinese key phrase extraction tool**. -->

<!--
| resource name (Name) | description (Description) | link |
| :--- | :--- | :--- |
| | | |
| | | |
| | | |
| | | |
| | | |
| | | |
| | | |
| | | |
| | | |
| | | |
| | | |
| | | |
| | | |
| | | |
| | | |
| | | | -->


<!-- <img align="right" src="https://github-readme-stats.vercel.app/api?username=fighting41love&show_icons=true&icon_color=CE1D2D&text_color=718096&bg_color=ffffff&hide_title=true" /> -->
